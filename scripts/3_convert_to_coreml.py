#!/usr/bin/env python3
"""
EfficientNet ëª¨ë¸ì„ Core MLë¡œ ì§ì ‘ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
PyTorch â†’ Core ML ì§ì ‘ ë³€í™˜
ìµœì‹  í›ˆë ¨ëœ EfficientNet ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ì„œ ë³€í™˜
"""

import sys
import torch
import numpy as np
from pathlib import Path
import traceback
import glob
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.models.efficientnet_watermelon import create_efficientnet_watermelon


def find_latest_efficientnet_model():
    """ìµœì‹  EfficientNet ì‹¤í—˜ í´ë”ì—ì„œ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°"""
    print("ğŸ” ìµœì‹  EfficientNet ëª¨ë¸ ê²€ìƒ‰ ì¤‘...")
    
    # EfficientNet ì‹¤í—˜ í´ë”ë“¤ ì°¾ê¸°
    experiment_pattern = "experiments/direct_efficientnet_*"
    experiment_dirs = glob.glob(experiment_pattern)
    
    if not experiment_dirs:
        raise FileNotFoundError(f"EfficientNet ì‹¤í—˜ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {experiment_pattern}")
    
    # ê°€ì¥ ìµœì‹  í´ë” ì°¾ê¸° (í´ë”ëª…ì˜ timestamp ê¸°ì¤€)
    latest_dir = max(experiment_dirs)
    print(f"ğŸ“‚ ìµœì‹  ì‹¤í—˜ í´ë”: {latest_dir}")
    
    # í•´ë‹¹ í´ë”ì—ì„œ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
    model_files = glob.glob(f"{latest_dir}/*.pth")
    
    if not model_files:
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {latest_dir}/*.pth")
    
    # ìµœê³  MAE ëª¨ë¸ ìš°ì„ , ì—†ìœ¼ë©´ ìµœê³  Loss ëª¨ë¸ ì‚¬ìš©
    best_mae_files = [f for f in model_files if "best_mae" in f]
    best_loss_files = [f for f in model_files if "best_loss" in f]
    
    if best_mae_files:
        model_path = best_mae_files[0]
        print(f"ğŸ¯ ìµœê³  MAE ëª¨ë¸ ì‚¬ìš©: {model_path}")
    elif best_loss_files:
        model_path = best_loss_files[0]
        print(f"ğŸ¯ ìµœê³  Loss ëª¨ë¸ ì‚¬ìš©: {model_path}")
    else:
        # ê°€ì¥ ìµœì‹  ëª¨ë¸ íŒŒì¼ ì‚¬ìš©
        model_path = max(model_files, key=lambda x: Path(x).stat().st_mtime)
        print(f"ğŸ¯ ìµœì‹  ëª¨ë¸ íŒŒì¼ ì‚¬ìš©: {model_path}")
    
    return model_path


def load_model():
    """í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ"""
    model_path = find_latest_efficientnet_model()
    
    print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(model_path, map_location='cpu')
    
    # ëª¨ë¸ ì„¤ì • í™•ì¸
    model_config = checkpoint.get('model_config', {})
    print(f"ğŸ“‹ ëª¨ë¸ ì„¤ì •: {model_config}")
    
    # EfficientNet ëª¨ë¸ ìƒì„±
    model = create_efficientnet_watermelon(
        model_name=model_config.get('model_name', 'efficientnet_b0'),
        pretrained=model_config.get('pretrained', False)
    )
    
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    print("âœ… EfficientNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    return model, model_path


def convert_to_coreml(model, output_path="models/converted/efficientnet.mlmodel"):
    """PyTorch ëª¨ë¸ì„ Core MLë¡œ ì§ì ‘ ë³€í™˜"""
    try:
        import coremltools as ct
        print("ğŸ”„ PyTorch â†’ Core ML ë³€í™˜ ì‹œì‘...")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ë”ë¯¸ ì…ë ¥ ìƒì„±
        dummy_input = torch.randn(1, 3, 224, 224)
        
        # PyTorch ëª¨ë¸ì„ traced modelë¡œ ë³€í™˜
        traced_model = torch.jit.trace(model, dummy_input)
        
        # Core ML ë³€í™˜
        coreml_model = ct.convert(
            traced_model,
            inputs=[ct.TensorType(shape=(1, 3, 224, 224), name="input")],
            outputs=[ct.TensorType(name="output")],
            compute_units=ct.ComputeUnit.CPU_AND_GPU,
            minimum_deployment_target=ct.target.iOS13
        )
        
        # ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì„¤ì • (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        try:
            coreml_model.short_description = "ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ (EfficientNet ê¸°ë°˜)"
            coreml_model.author = "Watermelon ML Team"
            coreml_model.license = "MIT"
            coreml_model.version = "1.0"
            
            # ì…ë ¥/ì¶œë ¥ ì„¤ëª… ì¶”ê°€
            coreml_model.input_description["input"] = "ë©œ-ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ (224x224x3)"
            coreml_model.output_description["output"] = "ì˜ˆì¸¡ëœ ë‹¹ë„ê°’ (Brix)"
        except Exception as meta_error:
            print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ì„¤ì • ì‹¤íŒ¨ (ëª¨ë¸ ë³€í™˜ì€ ì„±ê³µ): {meta_error}")
        
        # ëª¨ë¸ ì €ì¥
        coreml_model.save(str(output_path))
        
        print(f"âœ… Core ML ë³€í™˜ ì™„ë£Œ: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"âŒ Core ML ë³€í™˜ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None


def test_converted_model(model_path, original_model):
    """ë³€í™˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)"""
    try:
        import coremltools as ct
        print(f"ğŸ§ª ë³€í™˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸: {model_path}")
        
        # Core ML ëª¨ë¸ ë¡œë“œ
        coreml_model = ct.models.MLModel(str(model_path))
        
        # ë”ë¯¸ ì…ë ¥ ìƒì„±
        dummy_input = torch.randn(1, 3, 224, 224)
        
        # ì›ë³¸ PyTorch ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            original_output = original_model(dummy_input)
            original_pred = original_output.numpy().flatten()[0]
        
        # Core ML ëª¨ë¸ ì˜ˆì¸¡
        input_dict = {"input": dummy_input.numpy()}
        coreml_output = coreml_model.predict(input_dict)
        coreml_pred = list(coreml_output.values())[0][0]
        
        # ê²°ê³¼ ë¹„êµ
        diff = abs(original_pred - coreml_pred)
        print(f"   ğŸ“Š ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡: {original_pred:.6f}")
        print(f"   ğŸ“Š Core ML ì˜ˆì¸¡: {coreml_pred:.6f}")
        print(f"   ğŸ“Š ì°¨ì´: {diff:.6f}")
        
        if diff < 0.001:
            print("   âœ… ë³€í™˜ ì„±ê³µ! ì˜ˆì¸¡ê°’ì´ ì¼ì¹˜í•©ë‹ˆë‹¤.")
        else:
            print("   âš ï¸ ë³€í™˜ëœ ëª¨ë¸ê³¼ ì›ë³¸ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì— ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        return True
        
    except Exception as e:
        print(f"   âŒ ë³€í™˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("   â„¹ï¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ëŠ” macOS í™˜ê²½ ë¬¸ì œì¼ ìˆ˜ ìˆìœ¼ë©°, iOSì—ì„œëŠ” ì •ìƒ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤.")
        return False


def main():
    """ë©”ì¸ ë³€í™˜ í•¨ìˆ˜"""
    print("ğŸ‰ EfficientNet ëª¨ë¸ â†’ Core ML ë³€í™˜!")
    print("="*50)
    
    try:
        # 1. ëª¨ë¸ ë¡œë“œ
        model, model_path = load_model()
        print(f"ğŸ“ ì‚¬ìš©í•  ëª¨ë¸: {model_path}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # 2. PyTorch â†’ Core ML ë³€í™˜
    print(f"\nğŸ”„ PyTorch â†’ Core ML ë³€í™˜ ì‹œì‘...")
    coreml_path = convert_to_coreml(model)
    
    if coreml_path:
        # 3. ë³€í™˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        print(f"\nğŸ§ª ë³€í™˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
        test_result = test_converted_model(coreml_path, model)
        
        if test_result:
            print("   âœ… ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ë„ ì„±ê³µ!")
        else:
            print("   âš ï¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤íŒ¨í–ˆì§€ë§Œ ëª¨ë¸ ë³€í™˜ì€ ì„±ê³µ!")
        
        print(f"\nğŸ‰ ë³€í™˜ ì™„ë£Œ! Core ML ëª¨ë¸: {coreml_path}")
        return coreml_path
    else:
        print(f"\nâŒ Core ML ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return None


if __name__ == "__main__":
    result = main()
    if result:
        print(f"\nâœ… ìµœì¢… ê²°ê³¼: {result}")
        print("ğŸ“± iOS ì•±ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    else:
        print(f"\nâŒ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") 