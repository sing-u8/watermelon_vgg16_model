#!/usr/bin/env python3
"""
ğŸ‰ Watermelon Ensemble Model Creation Script

ê¸°ì¡´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ì„ ì¡°í•©í•˜ì—¬ ì•™ìƒë¸” ëª¨ë¸ì„ ìƒì„±í•˜ê³  ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from pathlib import Path
import yaml
import json
import time
from typing import Dict, List, Tuple, Any, Optional
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
import sys
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from models.vgg_watermelon import VGGWatermelon, create_vgg_watermelon
from training.data_loader import create_data_loaders
from training.trainer import create_trainer_from_config
from evaluation.evaluator import WatermelonEvaluator


class WatermelonEnsemble:
    """
    ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ì„ ìœ„í•œ ì•™ìƒë¸” ëª¨ë¸ í´ë˜ìŠ¤
    """
    
    def __init__(self, models: List[VGGWatermelon], weights: Optional[List[float]] = None):
        """
        ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            models (List[VGGWatermelon]): ì•™ìƒë¸”ì— í¬í•¨í•  ëª¨ë¸ë“¤
            weights (List[float], optional): ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜
        """
        self.models = models
        self.weights = weights if weights else [1.0 / len(models)] * len(models)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ëª¨ë“  ëª¨ë¸ì„ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        for model in self.models:
            model.to(self.device)
            model.eval()
        
        print(f"ğŸ¯ ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        print(f"   ğŸ“Š ëª¨ë¸ ìˆ˜: {len(self.models)}")
        print(f"   âš–ï¸ ê°€ì¤‘ì¹˜: {[f'{w:.3f}' for w in self.weights]}")
        print(f"   ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {self.device}")
    
    def predict(self, x: torch.Tensor) -> torch.Tensor:
        """
        ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰
        
        Args:
            x (torch.Tensor): ì…ë ¥ í…ì„œ
            
        Returns:
            torch.Tensor: ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼
        """
        predictions = []
        
        with torch.no_grad():
            for model in self.models:
                pred = model(x)
                predictions.append(pred)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_pred = sum(w * pred for w, pred in zip(self.weights, predictions))
        
        return weighted_pred
    
    def evaluate_ensemble(self, data_loader) -> Dict[str, Any]:
        """
        ì•™ìƒë¸” ëª¨ë¸ í‰ê°€
        
        Args:
            data_loader: ë°ì´í„° ë¡œë”
            
        Returns:
            Dict[str, Any]: í‰ê°€ ë©”íŠ¸ë¦­ë“¤
        """
        all_predictions = []
        all_targets = []
        
        self.eval()
        
        with torch.no_grad():
            for inputs, targets in data_loader:
                inputs = inputs.to(self.device)
                targets = targets.to(self.device)
                
                # ì•™ìƒë¸” ì˜ˆì¸¡
                predictions = self.predict(inputs)
                
                all_predictions.extend(predictions.cpu().numpy())
                all_targets.extend(targets.cpu().numpy())
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        predictions = np.array(all_predictions)
        targets = np.array(all_targets)
        
        mae = mean_absolute_error(targets, predictions)
        mse = mean_squared_error(targets, predictions)
        rmse = np.sqrt(mse)
        r2 = r2_score(targets, predictions)
        
        # í—ˆìš© ì˜¤ì°¨ë³„ ì •í™•ë„ ê³„ì‚°
        accuracy_05 = np.mean(np.abs(predictions - targets) <= 0.5) * 100
        accuracy_10 = np.mean(np.abs(predictions - targets) <= 1.0) * 100
        
        return {
            'mae': mae,
            'mse': mse,
            'rmse': rmse,
            'r2_score': r2,
            'accuracy_0.5': accuracy_05,
            'accuracy_1.0': accuracy_10,
            'predictions': predictions.tolist(),
            'targets': targets.tolist()
        }
    
    def eval(self):
        """ëª¨ë“  ëª¨ë¸ì„ evaluation ëª¨ë“œë¡œ ì„¤ì •"""
        for model in self.models:
            model.eval()


def train_individual_models(experiment_configs: List[str], 
                          data_path: str,
                          quick_training: bool = True) -> List[str]:
    """
    ê°œë³„ ëª¨ë¸ë“¤ì„ í›ˆë ¨ì‹œí‚¤ê³  ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë°˜í™˜
    
    Args:
        experiment_configs (List[str]): ì‹¤í—˜ ì„¤ì • íŒŒì¼ ê²½ë¡œë“¤
        data_path (str): ë°ì´í„° ê²½ë¡œ
        quick_training (bool): ë¹ ë¥¸ í›ˆë ¨ ëª¨ë“œ (ì—í¬í¬ ìˆ˜ ì¤„ì„)
        
    Returns:
        List[str]: í›ˆë ¨ëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë“¤
    """
    model_paths = []
    
    for i, config_path in enumerate(experiment_configs):
        print(f"\nğŸ‹ï¸ ëª¨ë¸ {i+1}/{len(experiment_configs)} í›ˆë ¨ ì‹œì‘")
        print(f"   ğŸ“„ ì„¤ì •: {config_path}")
        
        # ì‹¤í—˜ ì´ë¦„ ìƒì„±
        config_name = Path(config_path).stem
        experiment_name = f"ensemble_{config_name}_{int(time.time())}"
        
        # ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•´ ì„¤ì • ìˆ˜ì •
        if quick_training:
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            # ì—í¬í¬ ìˆ˜ ì¤„ì´ê¸°
            config['training']['epochs'] = min(10, config['training'].get('epochs', 100))
            config['early_stopping']['patience'] = 5
            
            # ì„ì‹œ ì„¤ì • íŒŒì¼ ìƒì„±
            temp_config_path = f"configs/temp_{config_name}.yaml"
            with open(temp_config_path, 'w') as f:
                yaml.dump(config, f)
            
            config_path = temp_config_path
        
        try:
            # íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í›ˆë ¨
            trainer = create_trainer_from_config(config_path, data_path, experiment_name)
            results = trainer.train(
                num_epochs=10 if quick_training else None,
                verbose=False
            )
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê²½ë¡œ ì €ì¥
            model_path = trainer.best_model_path
            if Path(model_path).exists():
                model_paths.append(str(model_path))
                print(f"   âœ… í›ˆë ¨ ì™„ë£Œ - MAE: {results['best_val_mae']:.3f}")
            else:
                print(f"   âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_path}")
        
        except Exception as e:
            print(f"   âŒ í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
            continue
        
        finally:
            # ì„ì‹œ ì„¤ì • íŒŒì¼ ì‚­ì œ
            if quick_training and 'temp_' in config_path:
                Path(config_path).unlink(missing_ok=True)
    
    return model_paths


def create_ensemble_from_existing_configs(data_path: str, save_dir: str = "experiments/ensemble") -> Dict[str, Any]:
    """
    ê¸°ì¡´ ì„±ê³µí•œ ì‹¤í—˜ ì„¤ì •ë“¤ë¡œë¶€í„° ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
    
    Args:
        data_path (str): ë°ì´í„° ê²½ë¡œ
        save_dir (str): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        Dict[str, Any]: ì•™ìƒë¸” ê²°ê³¼
    """
    print("ğŸ¯ ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ì‹œì‘")
    
    # ê¸°ì¡´ ì„±ê³µí•œ ì‹¤í—˜ ì„¤ì •ë“¤
    successful_configs = [
        "configs/training_batch16.yaml",    # Val MAE: 0.7103, Test MAE: 1.5267 (ìµœê³  ì¼ë°˜í™”)
        "configs/training_batch32.yaml",    # Val MAE: 0.5462, Test MAE: 1.7936 (ìµœê³  ê²€ì¦)
        "configs/training_huber_loss.yaml", # Val MAE: 0.6119, Test MAE: 1.7399 (ê°•ê±´ì„±)
    ]
    
    # ì„¤ì • íŒŒì¼ ì¡´ì¬ í™•ì¸
    existing_configs = []
    for config_path in successful_configs:
        if Path(config_path).exists():
            existing_configs.append(config_path)
        else:
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_path}")
    
    if not existing_configs:
        raise FileNotFoundError("ì‚¬ìš© ê°€ëŠ¥í•œ ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"âœ… ì‚¬ìš©í•  ì„¤ì • íŒŒì¼: {len(existing_configs)}ê°œ")
    
    # ê°œë³„ ëª¨ë¸ë“¤ í›ˆë ¨
    print("\nğŸ‹ï¸ ê°œë³„ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    model_paths = train_individual_models(existing_configs, data_path, quick_training=True)
    
    if not model_paths:
        raise RuntimeError("í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"âœ… í›ˆë ¨ëœ ëª¨ë¸: {len(model_paths)}ê°œ")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    data_loader = create_data_loaders(data_path, config_path=existing_configs[0])
    
    # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    print("\nğŸ“Š ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...")
    individual_results = {}
    models = []
    
    for i, model_path in enumerate(model_paths):
        try:
            # ëª¨ë¸ ë¡œë“œ (PyTorch 2.6 í˜¸í™˜ì„±ì„ ìœ„í•´ weights_only=False ëª…ì‹œ)
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
            model_config = checkpoint.get('model_config', {})
            
            # VGGWatermelonì´ ì§€ì›í•˜ëŠ” íŒŒë¼ë¯¸í„°ë§Œ í•„í„°ë§
            supported_params = [
                'input_channels', 'pretrained', 'dropout_rate', 
                'freeze_features', 'num_fc_layers', 'fc_hidden_size'
            ]
            filtered_config = {k: v for k, v in model_config.items() if k in supported_params}
            
            model = create_vgg_watermelon(**filtered_config)
            model.load_state_dict(checkpoint['model_state_dict'])
            models.append(model)
            
            # ê°œë³„ ëª¨ë¸ í‰ê°€
            ensemble = WatermelonEnsemble([model])
            results = ensemble.evaluate_ensemble(data_loader.test_loader)
            
            model_name = f"Model_{i+1}"
            individual_results[model_name] = results
            
            print(f"   {model_name}: MAE={results['mae']:.3f}, RÂ²={results['r2_score']:.3f}")
            
        except Exception as e:
            print(f"   âŒ ëª¨ë¸ {i+1} í‰ê°€ ì‹¤íŒ¨: {str(e)}")
            continue
    
    if not models:
        raise RuntimeError("ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ë° í‰ê°€
    print("\nğŸ¯ ì•™ìƒë¸” ëª¨ë¸ í‰ê°€...")
    
    # 1. Equal Weight Ensemble
    equal_ensemble = WatermelonEnsemble(models)
    equal_results = equal_ensemble.evaluate_ensemble(data_loader.test_loader)
    
    # 2. Performance-based Weighted Ensemble
    weights = []
    for model_name, results in individual_results.items():
        # MAEê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜ (1/MAE ì •ê·œí™”)
        weight = 1.0 / results['mae']
        weights.append(weight)
    
    # ê°€ì¤‘ì¹˜ ì •ê·œí™”
    total_weight = sum(weights)
    weights = [w / total_weight for w in weights]
    
    weighted_ensemble = WatermelonEnsemble(models, weights)
    weighted_results = weighted_ensemble.evaluate_ensemble(data_loader.test_loader)
    
    # ê²°ê³¼ ì •ë¦¬
    ensemble_results = {
        'individual_models': individual_results,
        'equal_weight_ensemble': equal_results,
        'weighted_ensemble': weighted_results,
        'weights': weights,
        'model_count': len(models)
    }
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š ì•™ìƒë¸” ê²°ê³¼:")
    print(f"   ğŸŸ° Equal Weight - MAE: {equal_results['mae']:.3f}, "
          f"Acc(Â±0.5): {equal_results['accuracy_0.5']:.1f}%, "
          f"Acc(Â±1.0): {equal_results['accuracy_1.0']:.1f}%")
    print(f"   âš–ï¸ Weighted     - MAE: {weighted_results['mae']:.3f}, "
          f"Acc(Â±0.5): {weighted_results['accuracy_0.5']:.1f}%, "
          f"Acc(Â±1.0): {weighted_results['accuracy_1.0']:.1f}%")
    
    # ê²°ê³¼ ì €ì¥
    save_dir_path = Path(save_dir)
    save_dir_path.mkdir(parents=True, exist_ok=True)
    
    # JSON ê²°ê³¼ ì €ì¥
    results_path = save_dir_path / "ensemble_results.json"
    with open(results_path, 'w') as f:
        json.dump(ensemble_results, f, indent=2)
    
    # ì‹œê°í™”
    create_ensemble_visualization(ensemble_results, save_dir_path)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {save_dir}")
    
    return ensemble_results


def create_ensemble_visualization(results: Dict[str, Any], save_dir: Path):
    """
    ì•™ìƒë¸” ê²°ê³¼ ì‹œê°í™”
    
    Args:
        results (Dict): ì•™ìƒë¸” ê²°ê³¼
        save_dir (Path): ì €ì¥ ë””ë ‰í† ë¦¬
    """
    plt.style.use('default')
    
    # 1. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # MAE ë¹„êµ
    models = list(results['individual_models'].keys()) + ['Equal Ensemble', 'Weighted Ensemble']
    mae_values = [results['individual_models'][m]['mae'] for m in results['individual_models'].keys()]
    mae_values += [results['equal_weight_ensemble']['mae'], results['weighted_ensemble']['mae']]
    
    colors = ['lightblue'] * len(results['individual_models']) + ['orange', 'red']
    
    axes[0, 0].bar(range(len(models)), mae_values, color=colors)
    axes[0, 0].set_title('Model Performance Comparison (MAE)', fontsize=14, fontweight='bold')
    axes[0, 0].set_ylabel('Mean Absolute Error (Brix)')
    axes[0, 0].set_xticks(range(len(models)))
    axes[0, 0].set_xticklabels(models, rotation=45, ha='right')
    axes[0, 0].grid(True, alpha=0.3)
    
    # Accuracy ë¹„êµ (Â±0.5 Brix)
    acc_05_values = [results['individual_models'][m]['accuracy_0.5'] for m in results['individual_models'].keys()]
    acc_05_values += [results['equal_weight_ensemble']['accuracy_0.5'], results['weighted_ensemble']['accuracy_0.5']]
    
    axes[0, 1].bar(range(len(models)), acc_05_values, color=colors)
    axes[0, 1].set_title('Accuracy Comparison (Â±0.5 Brix)', fontsize=14, fontweight='bold')
    axes[0, 1].set_ylabel('Accuracy (%)')
    axes[0, 1].set_xticks(range(len(models)))
    axes[0, 1].set_xticklabels(models, rotation=45, ha='right')
    axes[0, 1].grid(True, alpha=0.3)
    
    # ì˜ˆì¸¡ vs ì‹¤ì œ (Weighted Ensemble)
    predictions = np.array(results['weighted_ensemble']['predictions'])
    targets = np.array(results['weighted_ensemble']['targets'])
    
    axes[1, 0].scatter(targets, predictions, alpha=0.6, color='red')
    axes[1, 0].plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'k--', lw=2)
    axes[1, 0].set_xlabel('Actual Sweetness (Brix)')
    axes[1, 0].set_ylabel('Predicted Sweetness (Brix)')
    axes[1, 0].set_title('Weighted Ensemble: Prediction vs Actual', fontsize=14, fontweight='bold')
    axes[1, 0].grid(True, alpha=0.3)
    
    # ì˜¤ì°¨ ë¶„í¬
    errors = predictions - targets
    # 1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ë‹¨ì¼ ë°ì´í„°ì…‹ìœ¼ë¡œ ì¸ì‹í•˜ê²Œ í•¨
    errors_flat = errors.flatten()
    axes[1, 1].hist(errors_flat, bins=15, alpha=0.7, color='skyblue', edgecolor='black')
    axes[1, 1].axvline(x=0, color='red', linestyle='--', linewidth=2)
    axes[1, 1].set_xlabel('Prediction Error (Brix)')
    axes[1, 1].set_ylabel('Frequency')
    axes[1, 1].set_title('Weighted Ensemble: Error Distribution', fontsize=14, fontweight='bold')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_dir / "ensemble_performance.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    print("ğŸ“Š ì‹œê°í™” ì €ì¥ë¨: ensemble_performance.png")


def optimize_preprocessing_parameters(data_path: str, save_dir: str = "experiments/preprocessing_optimization"):
    """
    ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í—˜
    
    Args:
        data_path (str): ë°ì´í„° ê²½ë¡œ
        save_dir (str): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    """
    print("\nğŸ”§ ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
    
    # ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ì„¤ì •ë“¤
    preprocessing_configs = [
        {
            'name': 'baseline',
            'n_mels': 128,
            'n_fft': 2048,
            'hop_length': 512,
            'description': 'ê¸°ë³¸ ì„¤ì •'
        },
        {
            'name': 'high_resolution',
            'n_mels': 256,
            'n_fft': 4096,
            'hop_length': 512,
            'description': 'ê³ í•´ìƒë„ ìŠ¤í™íŠ¸ë¡œê·¸ë¨'
        },
        {
            'name': 'low_complexity',
            'n_mels': 64,
            'n_fft': 1024,
            'hop_length': 256,
            'description': 'ì €ë³µì¡ë„ ì„¤ì •'
        },
        {
            'name': 'fine_temporal',
            'n_mels': 128,
            'n_fft': 2048,
            'hop_length': 256,
            'description': 'ì„¸ë°€í•œ ì‹œê°„ í•´ìƒë„'
        }
    ]
    
    results = {}
    
    for config in preprocessing_configs:
        print(f"\nğŸ“Š {config['name']} ì„¤ì • í…ŒìŠ¤íŠ¸ ì¤‘...")
        print(f"   ğŸ“ ì„¤ëª…: {config['description']}")
        print(f"   ğŸ”§ íŒŒë¼ë¯¸í„°: n_mels={config['n_mels']}, n_fft={config['n_fft']}, hop_length={config['hop_length']}")
        
        try:
            # ì„ì‹œ ë°ì´í„° ì„¤ì • íŒŒì¼ ìƒì„±
            temp_data_config = {
                'spectrogram': {
                    'n_mels': config['n_mels'],
                    'n_fft': config['n_fft'],
                    'hop_length': config['hop_length'],
                    'resize': {'enabled': True, 'height': 224, 'width': 224}
                }
            }
            
            temp_config_path = f"configs/temp_data_{config['name']}.yaml"
            with open(temp_config_path, 'w') as f:
                yaml.dump(temp_data_config, f)
            
            # ë¹ ë¥¸ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
            trainer_config = "configs/training_batch16.yaml"  # ê°€ì¥ ë¹ ë¥¸ ì„¤ì • ì‚¬ìš©
            
            with open(trainer_config, 'r') as f:
                training_config = yaml.safe_load(f)
            
            # ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•œ ì„¤ì • ìˆ˜ì •
            training_config['training']['epochs'] = 5
            training_config['early_stopping']['patience'] = 3
            
            temp_training_config = f"configs/temp_training_{config['name']}.yaml"
            with open(temp_training_config, 'w') as f:
                yaml.dump(training_config, f)
            
            # ëª¨ë¸ í›ˆë ¨
            experiment_name = f"preprocessing_{config['name']}_{int(time.time())}"
            trainer = create_trainer_from_config(temp_training_config, data_path, experiment_name)
            
            training_results = trainer.train(num_epochs=5, verbose=False)
            
            results[config['name']] = {
                'config': config,
                'val_mae': training_results['best_val_mae'],
                'test_mae': training_results['final_test_metrics'].get('mae', 'N/A'),
                'training_time': training_results['training_time']
            }
            
            print(f"   âœ… ì™„ë£Œ - Val MAE: {training_results['best_val_mae']:.3f}")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            Path(temp_config_path).unlink(missing_ok=True)
            Path(temp_training_config).unlink(missing_ok=True)
            
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {str(e)}")
            continue
    
    # ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥
    if results:
        save_dir_path = Path(save_dir)
        save_dir_path.mkdir(parents=True, exist_ok=True)
        
        # ê²°ê³¼ ì €ì¥
        results_path = save_dir_path / "preprocessing_optimization_results.json"
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        # ìµœê³  ì„±ëŠ¥ ì„¤ì • ì°¾ê¸°
        best_config = min(results.items(), key=lambda x: x[1]['val_mae'])
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ì „ì²˜ë¦¬ ì„¤ì •: {best_config[0]}")
        print(f"   ğŸ“Š Val MAE: {best_config[1]['val_mae']:.3f}")
        print(f"   ğŸ”§ íŒŒë¼ë¯¸í„°: {best_config[1]['config']}")
        
        print(f"\nğŸ’¾ ì „ì²˜ë¦¬ ìµœì í™” ê²°ê³¼ ì €ì¥ë¨: {save_dir}")
        
        return results
    else:
        print("âŒ ì „ì²˜ë¦¬ ìµœì í™” ì‹¤í—˜ì—ì„œ ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ - ì•™ìƒë¸” ëª¨ë¸ë§ & ì „ì²˜ë¦¬ ìµœì í™”")
    print("=" * 60)
    
    # ì„¤ì •
    data_path = "watermelon_sound_data"
    base_save_dir = "experiments"
    
    # ëª…ë ¹í–‰ ì¸ì í™•ì¸ (ì „ì²˜ë¦¬ ìµœì í™”ë§Œ ì‹¤í–‰í• ì§€ ì—¬ë¶€)
    import sys
    preprocessing_only = "--preprocessing-only" in sys.argv
    
    try:
        ensemble_results = {}
        
        if not preprocessing_only:
            # 1. ì•™ìƒë¸” ëª¨ë¸ë§
            print("\nğŸ¯ 1ë‹¨ê³„: ì•™ìƒë¸” ëª¨ë¸ë§")
            ensemble_results = create_ensemble_from_existing_configs(
                data_path, 
                f"{base_save_dir}/ensemble_optimization"
            )
        else:
            print("\nâš¡ ì „ì²˜ë¦¬ ìµœì í™”ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        
        # 2. ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ìµœì í™”
        print("\nğŸ”§ 2ë‹¨ê³„: ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ìµœì í™”")
        preprocessing_results = optimize_preprocessing_parameters(
            data_path, 
            f"{base_save_dir}/preprocessing_optimization"
        )
        
        # 3. ì¢…í•© ê²°ê³¼ ì •ë¦¬
        print("\nğŸ“‹ 3ë‹¨ê³„: ì¢…í•© ê²°ê³¼ ì •ë¦¬")
        
        if ensemble_results and 'individual_models' in ensemble_results:
            # ìµœê³  ì„±ëŠ¥ ì¶”ì¶œ
            best_individual = min(ensemble_results['individual_models'].items(), 
                                key=lambda x: x[1]['mae'])
            
            equal_ensemble = ensemble_results['equal_weight_ensemble']
            weighted_ensemble = ensemble_results['weighted_ensemble']
            
            print("\nğŸ† ìµœì¢… ì„±ëŠ¥ ë¹„êµ:")
            print(f"   ğŸ¥‰ ìµœê³  ê°œë³„ ëª¨ë¸: MAE={best_individual[1]['mae']:.3f}, Acc(Â±0.5)={best_individual[1]['accuracy_0.5']:.1f}%")
            print(f"   ğŸ¥ˆ Equal Ensemble: MAE={equal_ensemble['mae']:.3f}, Acc(Â±0.5)={equal_ensemble['accuracy_0.5']:.1f}%")
            print(f"   ğŸ¥‡ Weighted Ensemble: MAE={weighted_ensemble['mae']:.3f}, Acc(Â±0.5)={weighted_ensemble['accuracy_0.5']:.1f}%")
            
            # 90% ì •í™•ë„ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
            target_accuracy_90 = 90.0
            
            print(f"\nğŸ¯ 90% ì •í™•ë„ ëª©í‘œ ë‹¬ì„± ë¶„ì„:")
            for name, acc in [
                ("ìµœê³  ê°œë³„ ëª¨ë¸", best_individual[1]['accuracy_0.5']),
                ("Equal Ensemble", equal_ensemble['accuracy_0.5']),
                ("Weighted Ensemble", weighted_ensemble['accuracy_0.5'])
            ]:
                status = "âœ… ë‹¬ì„±" if acc >= target_accuracy_90 else f"âŒ ë¯¸ë‹¬ ({target_accuracy_90 - acc:.1f}%p ë¶€ì¡±)"
                print(f"   {name}: {acc:.1f}% - {status}")
        else:
            print("ğŸ“ ì•™ìƒë¸” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤ (ì „ì²˜ë¦¬ ìµœì í™”ë§Œ ì‹¤í–‰ë¨)")
        
        # ì „ì²˜ë¦¬ ìµœì í™” ê²°ê³¼
        if preprocessing_results:
            best_preprocessing = min(preprocessing_results.items(), key=lambda x: x[1]['val_mae'])
            print(f"\nğŸ”§ ìµœì  ì „ì²˜ë¦¬ ì„¤ì •: {best_preprocessing[0]} (MAE: {best_preprocessing[1]['val_mae']:.3f})")
        
        print("\nâœ… ëª¨ë“  ìµœì í™” ì‘ì—… ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 