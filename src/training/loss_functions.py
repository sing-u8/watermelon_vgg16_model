"""
Loss Functions Module
ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ì„ ìœ„í•œ ì†ì‹¤ í•¨ìˆ˜ ëª¨ë“ˆ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any
import numpy as np


class RegressionLoss(nn.Module):
    """
    íšŒê·€ ë¬¸ì œë¥¼ ìœ„í•œ í†µí•© ì†ì‹¤ í•¨ìˆ˜ í´ë˜ìŠ¤
    """
    
    def __init__(self, 
                 loss_type: str = 'mse',
                 reduction: str = 'mean',
                 huber_delta: float = 1.0,
                 quantile_alpha: float = 0.5,
                 weights: Optional[torch.Tensor] = None):
        """
        RegressionLoss ì´ˆê¸°í™”
        
        Args:
            loss_type (str): ì†ì‹¤ í•¨ìˆ˜ íƒ€ì… ('mse', 'mae', 'huber', 'smooth_l1', 'quantile')
            reduction (str): ì¶•ì†Œ ë°©ì‹ ('mean', 'sum', 'none')
            huber_delta (float): Huber ì†ì‹¤ì—ì„œ ì‚¬ìš©í•  ë¸íƒ€ ê°’
            quantile_alpha (float): Quantile íšŒê·€ì—ì„œ ì‚¬ìš©í•  ì•ŒíŒŒ ê°’
            weights (torch.Tensor, optional): ìƒ˜í”Œë³„ ê°€ì¤‘ì¹˜
        """
        super(RegressionLoss, self).__init__()
        
        self.loss_type = loss_type.lower()
        self.reduction = reduction
        self.huber_delta = huber_delta
        self.quantile_alpha = quantile_alpha
        self.weights = weights
        
        # ì§€ì›í•˜ëŠ” ì†ì‹¤ í•¨ìˆ˜ íƒ€ì…
        self.supported_losses = ['mse', 'mae', 'huber', 'smooth_l1', 'quantile', 'mape']
        
        if self.loss_type not in self.supported_losses:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì†ì‹¤ í•¨ìˆ˜: {loss_type}. "
                           f"ì§€ì›ë˜ëŠ” íƒ€ì…: {self.supported_losses}")
    
    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        ì†ì‹¤ ê³„ì‚°
        
        Args:
            predictions (torch.Tensor): ëª¨ë¸ ì˜ˆì¸¡ê°’ [batch_size, 1] ë˜ëŠ” [batch_size]
            targets (torch.Tensor): ì‹¤ì œ íƒ€ê²Ÿê°’ [batch_size, 1] ë˜ëŠ” [batch_size]
            
        Returns:
            torch.Tensor: ê³„ì‚°ëœ ì†ì‹¤
        """
        # í…ì„œ ì°¨ì› ì •ê·œí™”
        predictions = predictions.squeeze()
        targets = targets.squeeze()
        
        # ë°°ì¹˜ í¬ê¸° í™•ì¸
        if predictions.shape != targets.shape:
            raise ValueError(f"ì˜ˆì¸¡ê°’ê³¼ íƒ€ê²Ÿê°’ì˜ í¬ê¸°ê°€ ë‹¤ë¦…ë‹ˆë‹¤: "
                           f"{predictions.shape} vs {targets.shape}")
        
        # ì†ì‹¤ í•¨ìˆ˜ë³„ë¡œ ê³„ì‚°
        if self.loss_type == 'mse':
            loss = self._mse_loss(predictions, targets)
        elif self.loss_type == 'mae':
            loss = self._mae_loss(predictions, targets)
        elif self.loss_type == 'huber':
            loss = self._huber_loss(predictions, targets)
        elif self.loss_type == 'smooth_l1':
            loss = self._smooth_l1_loss(predictions, targets)
        elif self.loss_type == 'quantile':
            loss = self._quantile_loss(predictions, targets)
        elif self.loss_type == 'mape':
            loss = self._mape_loss(predictions, targets)
        else:
            raise ValueError(f"êµ¬í˜„ë˜ì§€ ì•Šì€ ì†ì‹¤ í•¨ìˆ˜: {self.loss_type}")
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        if self.weights is not None:
            weights = self.weights.to(loss.device)
            if weights.shape[0] != loss.shape[0]:
                raise ValueError(f"ê°€ì¤‘ì¹˜ í¬ê¸°ê°€ ë°°ì¹˜ í¬ê¸°ì™€ ë‹¤ë¦…ë‹ˆë‹¤: "
                               f"{weights.shape[0]} vs {loss.shape[0]}")
            loss = loss * weights
        
        # ì¶•ì†Œ ì ìš©
        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss
    
    def _mse_loss(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """í‰ê·  ì œê³± ì˜¤ì°¨ (MSE) ê³„ì‚°"""
        return F.mse_loss(predictions, targets, reduction='none')
    
    def _mae_loss(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE) ê³„ì‚°"""
        return F.l1_loss(predictions, targets, reduction='none')
    
    def _huber_loss(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """Huber ì†ì‹¤ ê³„ì‚°"""
        return F.huber_loss(predictions, targets, delta=self.huber_delta, reduction='none')
    
    def _smooth_l1_loss(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """Smooth L1 ì†ì‹¤ ê³„ì‚°"""
        return F.smooth_l1_loss(predictions, targets, reduction='none')
    
    def _quantile_loss(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """Quantile ì†ì‹¤ ê³„ì‚°"""
        residuals = targets - predictions
        loss = torch.max(
            self.quantile_alpha * residuals,
            (self.quantile_alpha - 1) * residuals
        )
        return loss
    
    def _mape_loss(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ (MAPE) ê³„ì‚°"""
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        epsilon = 1e-8
        return torch.abs((targets - predictions) / (targets + epsilon)) * 100


class WeightedMSELoss(nn.Module):
    """
    ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ MSE ì†ì‹¤
    ë‹¹ë„ê°’ì— ë”°ë¼ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•  ìˆ˜ ìˆìŒ
    """
    
    def __init__(self, sweetness_ranges: Optional[Dict[str, tuple]] = None):
        """
        WeightedMSELoss ì´ˆê¸°í™”
        
        Args:
            sweetness_ranges (Dict, optional): ë‹¹ë„ ë²”ìœ„ë³„ ê°€ì¤‘ì¹˜
                ì˜ˆ: {'low': (8.0, 10.0, 1.2), 'medium': (10.0, 11.5, 1.0), 'high': (11.5, 13.0, 1.5)}
        """
        super(WeightedMSELoss, self).__init__()
        
        if sweetness_ranges is None:
            # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì„¤ì • (ê·¹ê°’ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
            self.sweetness_ranges = {
                'low': (8.0, 9.5, 1.2),      # ë‚®ì€ ë‹¹ë„: ê°€ì¤‘ì¹˜ 1.2
                'medium': (9.5, 11.0, 1.0),  # ì¤‘ê°„ ë‹¹ë„: ê°€ì¤‘ì¹˜ 1.0
                'high': (11.0, 13.0, 1.3)    # ë†’ì€ ë‹¹ë„: ê°€ì¤‘ì¹˜ 1.3
            }
        else:
            self.sweetness_ranges = sweetness_ranges
    
    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ MSE ì†ì‹¤ ê³„ì‚°
        
        Args:
            predictions (torch.Tensor): ëª¨ë¸ ì˜ˆì¸¡ê°’
            targets (torch.Tensor): ì‹¤ì œ íƒ€ê²Ÿê°’
            
        Returns:
            torch.Tensor: ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ MSE ì†ì‹¤
        """
        predictions = predictions.squeeze()
        targets = targets.squeeze()
        
        # ê¸°ë³¸ MSE ê³„ì‚°
        mse_loss = F.mse_loss(predictions, targets, reduction='none')
        
        # ë‹¹ë„ê°’ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ê³„ì‚°
        weights = torch.ones_like(targets)
        
        for range_name, (min_val, max_val, weight) in self.sweetness_ranges.items():
            mask = (targets >= min_val) & (targets < max_val)
            weights[mask] = weight
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        weighted_loss = mse_loss * weights
        
        return weighted_loss.mean()


class CombinedLoss(nn.Module):
    """
    ì—¬ëŸ¬ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì¡°í•©í•œ ì†ì‹¤ í•¨ìˆ˜
    """
    
    def __init__(self, 
                 loss_configs: Dict[str, Dict[str, Any]],
                 loss_weights: Optional[Dict[str, float]] = None):
        """
        CombinedLoss ì´ˆê¸°í™”
        
        Args:
            loss_configs (Dict): ì†ì‹¤ í•¨ìˆ˜ë³„ ì„¤ì •
                ì˜ˆ: {'mse': {'reduction': 'mean'}, 'mae': {'reduction': 'mean'}}
            loss_weights (Dict, optional): ì†ì‹¤ í•¨ìˆ˜ë³„ ê°€ì¤‘ì¹˜
                ì˜ˆ: {'mse': 0.7, 'mae': 0.3}
        """
        super(CombinedLoss, self).__init__()
        
        self.loss_functions = nn.ModuleDict()
        self.loss_weights = loss_weights or {}
        
        # ì†ì‹¤ í•¨ìˆ˜ ìƒì„±
        for loss_name, config in loss_configs.items():
            if loss_name in ['mse', 'mae', 'huber', 'smooth_l1', 'quantile', 'mape']:
                self.loss_functions[loss_name] = RegressionLoss(
                    loss_type=loss_name, **config
                )
            elif loss_name == 'weighted_mse':
                self.loss_functions[loss_name] = WeightedMSELoss(**config)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì†ì‹¤ í•¨ìˆ˜: {loss_name}")
        
        # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì„¤ì • (ê· ë“± ë¶„ë°°)
        if not self.loss_weights:
            num_losses = len(self.loss_functions)
            self.loss_weights = {name: 1.0/num_losses for name in self.loss_functions.keys()}
    
    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        ì¡°í•©ëœ ì†ì‹¤ ê³„ì‚°
        
        Args:
            predictions (torch.Tensor): ëª¨ë¸ ì˜ˆì¸¡ê°’
            targets (torch.Tensor): ì‹¤ì œ íƒ€ê²Ÿê°’
            
        Returns:
            torch.Tensor: ì¡°í•©ëœ ì†ì‹¤
        """
        total_loss = None
        
        for loss_name, loss_fn in self.loss_functions.items():
            loss_value = loss_fn(predictions, targets)
            weight = self.loss_weights.get(loss_name, 1.0)
            weighted_loss = weight * loss_value
            
            if total_loss is None:
                total_loss = weighted_loss
            else:
                total_loss = total_loss + weighted_loss
        
        return total_loss if total_loss is not None else torch.tensor(0.0)


def create_loss_function(loss_config: Dict[str, Any]) -> nn.Module:
    """
    ì„¤ì •ì— ë”°ë¥¸ ì†ì‹¤ í•¨ìˆ˜ ìƒì„±
    
    Args:
        loss_config (Dict): ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •
        
    Returns:
        nn.Module: ìƒì„±ëœ ì†ì‹¤ í•¨ìˆ˜
    """
    loss_type = loss_config.get('type', 'mse').lower()
    
    if loss_type in ['mse', 'mae', 'huber', 'smooth_l1', 'quantile', 'mape']:
        return RegressionLoss(
            loss_type=loss_type,
            reduction=loss_config.get('reduction', 'mean'),
            huber_delta=loss_config.get('huber_delta', 1.0),
            quantile_alpha=loss_config.get('quantile_alpha', 0.5)
        )
    
    elif loss_type == 'weighted_mse':
        return WeightedMSELoss(
            sweetness_ranges=loss_config.get('sweetness_ranges')
        )
    
    elif loss_type == 'combined':
        return CombinedLoss(
            loss_configs=loss_config.get('loss_configs', {}),
            loss_weights=loss_config.get('loss_weights')
        )
    
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì†ì‹¤ í•¨ìˆ˜ íƒ€ì…: {loss_type}")


def calculate_loss_weights(targets: torch.Tensor, 
                          num_bins: int = 5,
                          strategy: str = 'inverse_frequency') -> torch.Tensor:
    """
    íƒ€ê²Ÿê°’ ë¶„í¬ì— ë”°ë¥¸ ì†ì‹¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    
    Args:
        targets (torch.Tensor): íƒ€ê²Ÿê°’ë“¤
        num_bins (int): êµ¬ê°„ ìˆ˜
        strategy (str): ê°€ì¤‘ì¹˜ ê³„ì‚° ì „ëµ ('inverse_frequency', 'balanced')
        
    Returns:
        torch.Tensor: ê³„ì‚°ëœ ê°€ì¤‘ì¹˜
    """
    # íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
    min_val, max_val = targets.min().item(), targets.max().item()
    bins = torch.linspace(min_val, max_val, num_bins + 1)
    
    # ê° ìƒ˜í”Œì´ ì†í•œ êµ¬ê°„ ì°¾ê¸°
    bin_indices = torch.searchsorted(bins[1:], targets)
    bin_indices = torch.clamp(bin_indices, 0, num_bins - 1)
    
    # êµ¬ê°„ë³„ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
    bin_counts = torch.bincount(bin_indices, minlength=num_bins).float()
    
    # ê°€ì¤‘ì¹˜ ê³„ì‚°
    if strategy == 'inverse_frequency':
        # ë¹ˆë„ì˜ ì—­ìˆ˜ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°
        weights_per_bin = 1.0 / (bin_counts + 1e-8)
    elif strategy == 'balanced':
        # ê· í˜• ê°€ì¤‘ì¹˜ ê³„ì‚°
        total_samples = len(targets)
        weights_per_bin = total_samples / (num_bins * bin_counts + 1e-8)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ê°€ì¤‘ì¹˜ ì „ëµ: {strategy}")
    
    # ì •ê·œí™”
    weights_per_bin = weights_per_bin / weights_per_bin.mean()
    
    # ê° ìƒ˜í”Œì— ê°€ì¤‘ì¹˜ í• ë‹¹
    sample_weights = weights_per_bin[bin_indices]
    
    return sample_weights


def smoothed_loss(predictions: torch.Tensor, 
                  targets: torch.Tensor,
                  base_loss_fn: nn.Module,
                  smoothing_factor: float = 0.1) -> torch.Tensor:
    """
    ë¼ë²¨ ìŠ¤ë¬´ë”©ì´ ì ìš©ëœ ì†ì‹¤ í•¨ìˆ˜
    
    Args:
        predictions (torch.Tensor): ëª¨ë¸ ì˜ˆì¸¡ê°’
        targets (torch.Tensor): ì‹¤ì œ íƒ€ê²Ÿê°’
        base_loss_fn (nn.Module): ê¸°ë³¸ ì†ì‹¤ í•¨ìˆ˜
        smoothing_factor (float): ìŠ¤ë¬´ë”© ê°•ë„
        
    Returns:
        torch.Tensor: ìŠ¤ë¬´ë”©ì´ ì ìš©ëœ ì†ì‹¤
    """
    # ê¸°ë³¸ ì†ì‹¤ ê³„ì‚°
    base_loss = base_loss_fn(predictions, targets)
    
    # ê· ë“± ë¶„í¬ì™€ì˜ KL divergence ì¶”ê°€
    # íšŒê·€ ë¬¸ì œì—ì„œëŠ” íƒ€ê²Ÿê°’ ì£¼ë³€ì˜ ê°€ìš°ì‹œì•ˆ ë¶„í¬ë¡œ ìŠ¤ë¬´ë”©
    std = torch.std(targets)
    gaussian_noise = torch.randn_like(targets) * std * smoothing_factor
    smoothed_targets = targets + gaussian_noise
    
    smooth_loss = base_loss_fn(predictions, smoothed_targets)
    
    # ì¡°í•©
    return (1 - smoothing_factor) * base_loss + smoothing_factor * smooth_loss


if __name__ == "__main__":
    # ì†ì‹¤ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª ì†ì‹¤ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    batch_size = 32
    predictions = torch.randn(batch_size, 1) * 2 + 10  # 8~12 ë²”ìœ„
    targets = torch.randn(batch_size, 1) * 1.5 + 10.5  # ì‹¤ì œ ë‹¹ë„ê°’
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: ì˜ˆì¸¡ê°’ {predictions.shape}, íƒ€ê²Ÿê°’ {targets.shape}")
    
    # ë‹¤ì–‘í•œ ì†ì‹¤ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
    loss_types = ['mse', 'mae', 'huber', 'smooth_l1']
    
    for loss_type in loss_types:
        loss_fn = RegressionLoss(loss_type=loss_type)
        loss_value = loss_fn(predictions, targets)
        print(f"   {loss_type.upper()}: {loss_value.item():.4f}")
    
    # ê°€ì¤‘ì¹˜ ì ìš© MSE í…ŒìŠ¤íŠ¸
    weighted_mse = WeightedMSELoss()
    weighted_loss = weighted_mse(predictions, targets)
    print(f"   Weighted MSE: {weighted_loss.item():.4f}")
    
    # ì¡°í•© ì†ì‹¤ í…ŒìŠ¤íŠ¸
    combined_config = {
        'mse': {'reduction': 'mean'},
        'mae': {'reduction': 'mean'}
    }
    combined_weights = {'mse': 0.7, 'mae': 0.3}
    combined_loss = CombinedLoss(combined_config, combined_weights)
    combined_value = combined_loss(predictions, targets)
    print(f"   Combined (MSE+MAE): {combined_value.item():.4f}")
    
    print("âœ… ì†ì‹¤ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ") 