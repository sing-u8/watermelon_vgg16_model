"""
Model Analyzer
ëª¨ë¸ì˜ ìƒì„¸ ë¶„ì„ ë° ë¹„êµë¥¼ ìœ„í•œ ëª¨ë“ˆ
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Callable
from pathlib import Path
import json
import time
from tqdm import tqdm

# ìƒëŒ€ import
import sys
from pathlib import Path
current_dir = Path(__file__).parent
src_dir = current_dir.parent
sys.path.insert(0, str(src_dir))

from models.vgg_watermelon import VGGWatermelon
from training.data_loader import WatermelonDataLoader


class ModelAnalyzer:
    """
    ëª¨ë¸ì˜ ìƒì„¸ ë¶„ì„ì„ ìœ„í•œ í´ë˜ìŠ¤
    """
    
    def __init__(self, model: VGGWatermelon, device: torch.device):
        """
        ModelAnalyzer ì´ˆê¸°í™”
        
        Args:
            model (VGGWatermelon): ë¶„ì„í•  ëª¨ë¸
            device (torch.device): ë””ë°”ì´ìŠ¤
        """
        self.model = model.to(device)
        self.device = device
        
        print(f"ğŸ”¬ ModelAnalyzer ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ğŸ–¥ï¸ ë””ë°”ì´ìŠ¤: {self.device}")
    
    def analyze_model_architecture(self) -> Dict[str, Any]:
        """
        ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¶„ì„
        
        Returns:
            Dict[str, Any]: ì•„í‚¤í…ì²˜ ë¶„ì„ ê²°ê³¼
        """
        print("ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¶„ì„ ì¤‘...")
        
        # ê¸°ë³¸ ëª¨ë¸ ì •ë³´
        model_info = self.model.get_model_info()
        
        # ë ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„° ë¶„ì„
        layer_analysis = self._analyze_layers()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
        memory_analysis = self._analyze_memory_usage()
        
        # ê³„ì‚° ë³µì¡ë„ ë¶„ì„
        computational_analysis = self._analyze_computational_complexity()
        
        return {
            'model_info': model_info,
            'layer_analysis': layer_analysis,
            'memory_analysis': memory_analysis,
            'computational_analysis': computational_analysis
        }
    
    def _analyze_layers(self) -> Dict[str, Any]:
        """ë ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„° ë¶„ì„"""
        layer_info = {}
        
        for name, module in self.model.named_modules():
            if len(list(module.children())) == 0:  # leaf module
                params = sum(p.numel() for p in module.parameters())
                trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)
                
                layer_info[name] = {
                    'type': module.__class__.__name__,
                    'parameters': params,
                    'trainable_parameters': trainable_params,
                    'trainable_ratio': trainable_params / params if params > 0 else 0
                }
        
        return layer_info
    
    def _analyze_memory_usage(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„"""
        # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        dummy_input = torch.randn(1, 3, 224, 224).to(self.device)
        
        if torch.cuda.is_available() and self.device.type == 'cuda':
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()
            
            # ìˆœì „íŒŒ
            with torch.no_grad():
                _ = self.model(dummy_input)
            
            memory_allocated = torch.cuda.memory_allocated() / 1024**2  # MB
            memory_reserved = torch.cuda.memory_reserved() / 1024**2   # MB
            max_memory = torch.cuda.max_memory_allocated() / 1024**2   # MB
            
            return {
                'memory_allocated_mb': memory_allocated,
                'memory_reserved_mb': memory_reserved,
                'max_memory_allocated_mb': max_memory,
                'device': str(self.device)
            }
        else:
            return {
                'memory_allocated_mb': 0,
                'memory_reserved_mb': 0,
                'max_memory_allocated_mb': 0,
                'device': str(self.device),
                'note': 'CPU memory analysis not available'
            }
    
    def _analyze_computational_complexity(self) -> Dict[str, Any]:
        """ê³„ì‚° ë³µì¡ë„ ë¶„ì„"""
        # FLOPs ê³„ì‚°ì„ ìœ„í•œ ê°„ë‹¨í•œ ì¶”ì •
        total_params = sum(p.numel() for p in self.model.parameters())
        
        # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ì¶”ë¡  ì‹œê°„ ì¸¡ì •
        dummy_input = torch.randn(1, 3, 224, 224).to(self.device)
        
        # ì›Œë°ì—…
        with torch.no_grad():
            for _ in range(10):
                _ = self.model(dummy_input)
        
        # ì‹¤ì œ ì¸¡ì •
        inference_times = []
        with torch.no_grad():
            for _ in range(100):
                start_time = time.time()
                _ = self.model(dummy_input)
                if self.device.type == 'cuda':
                    torch.cuda.synchronize()
                inference_times.append(time.time() - start_time)
        
        return {
            'total_parameters': total_params,
            'avg_inference_time_ms': np.mean(inference_times) * 1000,
            'std_inference_time_ms': np.std(inference_times) * 1000,
            'min_inference_time_ms': np.min(inference_times) * 1000,
            'max_inference_time_ms': np.max(inference_times) * 1000,
            'throughput_fps': 1.0 / np.mean(inference_times)
        }
    
    def analyze_feature_maps(self, 
                           data_loader: WatermelonDataLoader,
                           num_samples: int = 10) -> Dict[str, Any]:
        """
        íŠ¹ì„± ë§µ ë¶„ì„
        
        Args:
            data_loader (WatermelonDataLoader): ë°ì´í„° ë¡œë”
            num_samples (int): ë¶„ì„í•  ìƒ˜í”Œ ìˆ˜
            
        Returns:
            Dict[str, Any]: íŠ¹ì„± ë§µ ë¶„ì„ ê²°ê³¼
        """
        print(f"ğŸ—ºï¸ íŠ¹ì„± ë§µ ë¶„ì„ ì¤‘ ({num_samples}ê°œ ìƒ˜í”Œ)...")
        
        self.model.eval()
        feature_stats = {}
        
        sample_count = 0
        with torch.no_grad():
            for inputs, targets in data_loader.test_loader:
                if sample_count >= num_samples:
                    break
                
                inputs = inputs.to(self.device)
                
                # ì—¬ëŸ¬ ë ˆì´ì–´ì—ì„œ íŠ¹ì„± ë§µ ì¶”ì¶œ
                layer_indices = [5, 10, 15, 20, 25]  # VGG-16ì˜ ì£¼ìš” ë ˆì´ì–´ë“¤
                
                for layer_idx in layer_indices:
                    try:
                        feature_map = self.model.get_feature_maps(inputs, layer_idx)
                        
                        if f'layer_{layer_idx}' not in feature_stats:
                            feature_stats[f'layer_{layer_idx}'] = {
                                'activations': [],
                                'shape': feature_map.shape[1:],  # ë°°ì¹˜ ì°¨ì› ì œì™¸
                                'layer_index': layer_idx
                            }
                        
                        # í‰ê·  í™œì„±í™” ê°’ ì €ì¥
                        avg_activation = feature_map.mean(dim=(2, 3)).cpu().numpy()  # ê³µê°„ ì°¨ì› í‰ê· 
                        feature_stats[f'layer_{layer_idx}']['activations'].append(avg_activation)
                        
                    except Exception as e:
                        print(f"Warning: ë ˆì´ì–´ {layer_idx} íŠ¹ì„± ë§µ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                
                sample_count += inputs.size(0)
        
        # í†µê³„ ê³„ì‚°
        for layer_name, stats in feature_stats.items():
            activations = np.concatenate(stats['activations'], axis=0)
            
            stats['statistics'] = {
                'mean_activation': float(np.mean(activations)),
                'std_activation': float(np.std(activations)),
                'min_activation': float(np.min(activations)),
                'max_activation': float(np.max(activations)),
                'num_channels': activations.shape[1],
                'sparsity': float(np.mean(activations == 0))  # 0ì¸ í™œì„±í™” ë¹„ìœ¨
            }
            
            # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì›ë³¸ ë°ì´í„° ì‚­ì œ
            del stats['activations']
        
        return feature_stats
    
    def analyze_gradients(self, 
                         data_loader: WatermelonDataLoader,
                         num_samples: int = 10) -> Dict[str, Any]:
        """
        ê·¸ë˜ë””ì–¸íŠ¸ ë¶„ì„
        
        Args:
            data_loader (WatermelonDataLoader): ë°ì´í„° ë¡œë”
            num_samples (int): ë¶„ì„í•  ìƒ˜í”Œ ìˆ˜
            
        Returns:
            Dict[str, Any]: ê·¸ë˜ë””ì–¸íŠ¸ ë¶„ì„ ê²°ê³¼
        """
        print(f"ğŸ“ˆ ê·¸ë˜ë””ì–¸íŠ¸ ë¶„ì„ ì¤‘ ({num_samples}ê°œ ìƒ˜í”Œ)...")
        
        self.model.train()  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ìœ„í•´ train ëª¨ë“œ
        
        gradient_stats = {}
        loss_fn = nn.MSELoss()
        
        sample_count = 0
        for inputs, targets in data_loader.val_loader:
            if sample_count >= num_samples:
                break
            
            inputs = inputs.to(self.device)
            targets = targets.to(self.device)
            
            # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
            self.model.zero_grad()
            
            # ìˆœì „íŒŒ ë° ì—­ì „íŒŒ
            predictions = self.model(inputs)
            loss = loss_fn(predictions, targets)
            loss.backward()
            
            # ê·¸ë˜ë””ì–¸íŠ¸ í†µê³„ ìˆ˜ì§‘
            for name, param in self.model.named_parameters():
                if param.grad is not None:
                    grad = param.grad.detach().cpu().numpy()
                    
                    if name not in gradient_stats:
                        gradient_stats[name] = {
                            'gradients': [],
                            'parameter_shape': param.shape
                        }
                    
                    gradient_stats[name]['gradients'].append(grad.flatten())
            
            sample_count += inputs.size(0)
        
        # ê·¸ë˜ë””ì–¸íŠ¸ í†µê³„ ê³„ì‚°
        for param_name, stats in gradient_stats.items():
            gradients = np.concatenate(stats['gradients'])
            
            stats['statistics'] = {
                'mean_gradient': float(np.mean(gradients)),
                'std_gradient': float(np.std(gradients)),
                'min_gradient': float(np.min(gradients)),
                'max_gradient': float(np.max(gradients)),
                'gradient_norm': float(np.linalg.norm(gradients)),
                'zero_gradient_ratio': float(np.mean(gradients == 0))
            }
            
            # ë©”ëª¨ë¦¬ ì ˆì•½
            del stats['gradients']
        
        self.model.eval()  # ë¶„ì„ í›„ eval ëª¨ë“œë¡œ ë³µê·€
        
        return gradient_stats
    
    def analyze_prediction_confidence(self, 
                                    data_loader: WatermelonDataLoader,
                                    num_bootstrap: int = 100) -> Dict[str, Any]:
        """
        ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„ (Bootstrap ê¸°ë°˜)
        
        Args:
            data_loader (WatermelonDataLoader): ë°ì´í„° ë¡œë”
            num_bootstrap (int): Bootstrap ë°˜ë³µ íšŸìˆ˜
            
        Returns:
            Dict[str, Any]: ì‹ ë¢°ë„ ë¶„ì„ ê²°ê³¼
        """
        print(f"ğŸ¯ ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„ ì¤‘ (Bootstrap: {num_bootstrap}íšŒ)...")
        
        self.model.eval()
        
        # ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜ì§‘
        all_predictions = []
        all_targets = []
        
        with torch.no_grad():
            for inputs, targets in data_loader.test_loader:
                inputs = inputs.to(self.device)
                predictions = self.model(inputs)
                
                all_predictions.extend(predictions.cpu().numpy().flatten())
                all_targets.extend(targets.numpy().flatten())
        
        all_predictions = np.array(all_predictions)
        all_targets = np.array(all_targets)
        
        # Bootstrap ë¶„ì„
        bootstrap_results = []
        n_samples = len(all_predictions)
        
        for _ in tqdm(range(num_bootstrap), desc="Bootstrap ë¶„ì„"):
            # ë³µì› ì¶”ì¶œ
            indices = np.random.choice(n_samples, size=n_samples, replace=True)
            boot_preds = all_predictions[indices]
            boot_targets = all_targets[indices]
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            mae = np.mean(np.abs(boot_preds - boot_targets))
            rmse = np.sqrt(np.mean((boot_preds - boot_targets) ** 2))
            r2 = 1 - np.sum((boot_targets - boot_preds) ** 2) / np.sum((boot_targets - np.mean(boot_targets)) ** 2)
            
            bootstrap_results.append({
                'mae': mae,
                'rmse': rmse,
                'r2': r2
            })
        
        # Bootstrap í†µê³„
        bootstrap_df = pd.DataFrame(bootstrap_results)
        
        confidence_analysis = {
            'bootstrap_statistics': {
                'mae': {
                    'mean': float(bootstrap_df['mae'].mean()),
                    'std': float(bootstrap_df['mae'].std()),
                    'ci_lower': float(bootstrap_df['mae'].quantile(0.025)),
                    'ci_upper': float(bootstrap_df['mae'].quantile(0.975))
                },
                'rmse': {
                    'mean': float(bootstrap_df['rmse'].mean()),
                    'std': float(bootstrap_df['rmse'].std()),
                    'ci_lower': float(bootstrap_df['rmse'].quantile(0.025)),
                    'ci_upper': float(bootstrap_df['rmse'].quantile(0.975))
                },
                'r2': {
                    'mean': float(bootstrap_df['r2'].mean()),
                    'std': float(bootstrap_df['r2'].std()),
                    'ci_lower': float(bootstrap_df['r2'].quantile(0.025)),
                    'ci_upper': float(bootstrap_df['r2'].quantile(0.975))
                }
            },
            'prediction_uncertainty': {
                'mean_prediction_std': float(np.std(all_predictions)),
                'prediction_range': float(np.max(all_predictions) - np.min(all_predictions)),
                'coefficient_of_variation': float(np.std(all_predictions) / np.mean(all_predictions))
            },
            'num_bootstrap_samples': num_bootstrap,
            'total_test_samples': n_samples
        }
        
        return confidence_analysis
    
    def benchmark_inference_speed(self, 
                                 batch_sizes: List[int] = [1, 4, 8, 16, 32],
                                 num_runs: int = 100) -> Dict[str, Any]:
        """
        ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ì—ì„œ ì¶”ë¡  ì†ë„ ë²¤ì¹˜ë§ˆí¬
        
        Args:
            batch_sizes (List[int]): í…ŒìŠ¤íŠ¸í•  ë°°ì¹˜ í¬ê¸°ë“¤
            num_runs (int): ê° ë°°ì¹˜ í¬ê¸°ë³„ ì‹¤í–‰ íšŸìˆ˜
            
        Returns:
            Dict[str, Any]: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        print(f"âš¡ ì¶”ë¡  ì†ë„ ë²¤ì¹˜ë§ˆí¬ ì¤‘...")
        
        self.model.eval()
        benchmark_results = {}
        
        for batch_size in batch_sizes:
            print(f"   ë°°ì¹˜ í¬ê¸° {batch_size} í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            dummy_input = torch.randn(batch_size, 3, 224, 224).to(self.device)
            
            # ì›Œë°ì—…
            with torch.no_grad():
                for _ in range(10):
                    _ = self.model(dummy_input)
            
            # ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬
            inference_times = []
            with torch.no_grad():
                for _ in range(num_runs):
                    start_time = time.time()
                    _ = self.model(dummy_input)
                    if self.device.type == 'cuda':
                        torch.cuda.synchronize()
                    inference_times.append(time.time() - start_time)
            
            benchmark_results[f'batch_size_{batch_size}'] = {
                'batch_size': batch_size,
                'avg_time_ms': np.mean(inference_times) * 1000,
                'std_time_ms': np.std(inference_times) * 1000,
                'min_time_ms': np.min(inference_times) * 1000,
                'max_time_ms': np.max(inference_times) * 1000,
                'throughput_samples_per_sec': batch_size / np.mean(inference_times),
                'time_per_sample_ms': np.mean(inference_times) * 1000 / batch_size
            }
        
        return benchmark_results
    
    def generate_analysis_report(self, 
                               data_loader: WatermelonDataLoader,
                               save_path: str = "model_analysis_report.json") -> str:
        """
        ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
        
        Args:
            data_loader (WatermelonDataLoader): ë°ì´í„° ë¡œë”
            save_path (str): ë³´ê³ ì„œ ì €ì¥ ê²½ë¡œ
            
        Returns:
            str: ì €ì¥ëœ ë³´ê³ ì„œ ê²½ë¡œ
        """
        print("ğŸ“Š ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # ê°ì¢… ë¶„ì„ ìˆ˜í–‰
        architecture_analysis = self.analyze_model_architecture()
        feature_analysis = self.analyze_feature_maps(data_loader, num_samples=20)
        gradient_analysis = self.analyze_gradients(data_loader, num_samples=10)
        confidence_analysis = self.analyze_prediction_confidence(data_loader, num_bootstrap=50)
        benchmark_results = self.benchmark_inference_speed()
        
        # ì¢…í•© ë³´ê³ ì„œ
        comprehensive_report = {
            'model_analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'architecture_analysis': architecture_analysis,
            'feature_map_analysis': feature_analysis,
            'gradient_analysis': gradient_analysis,
            'confidence_analysis': confidence_analysis,
            'performance_benchmark': benchmark_results
        }
        
        # ë³´ê³ ì„œ ì €ì¥
        save_path_obj = Path(save_path)
        save_path_obj.parent.mkdir(parents=True, exist_ok=True)
        
        with open(save_path_obj, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ ë¶„ì„ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {save_path_obj}")
        
        return str(save_path_obj) 