"""
EfficientNet ê¸°ë°˜ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸
ê°€ì¥ íš¨ìœ¨ì ì¸ íŒŒë¼ë¯¸í„° ëŒ€ë¹„ ì„±ëŠ¥ì„ ì œê³µí•˜ëŠ” ëª¨ë¸
"""

import torch
import torch.nn as nn
from torchvision import models
from typing import Dict, Any, Optional
import yaml
from pathlib import Path


class EfficientNetWatermelon(nn.Module):
    """
    EfficientNet ê¸°ë°˜ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸
    
    ì‘ì€ ë°ì´í„°ì…‹ì— ìµœì í™”ëœ ê²½ëŸ‰ ëª¨ë¸
    """
    
    def __init__(self, 
                 model_name: str = 'efficientnet_b0',
                 input_channels: int = 3,
                 pretrained: bool = True,
                 dropout_rate: float = 0.7,
                 freeze_features: bool = False,
                 num_fc_layers: int = 2,
                 fc_hidden_size: int = 256):
        """
        EfficientNetWatermelon ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_name (str): EfficientNet ëª¨ë¸ëª… (b0~b7)
            input_channels (int): ì…ë ¥ ì±„ë„ ìˆ˜
            pretrained (bool): ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€
            dropout_rate (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
            freeze_features (bool): íŠ¹ì„± ì¶”ì¶œ ë ˆì´ì–´ ê³ ì • ì—¬ë¶€
            num_fc_layers (int): ì™„ì „ ì—°ê²° ë ˆì´ì–´ ìˆ˜
            fc_hidden_size (int): ì™„ì „ ì—°ê²° ë ˆì´ì–´ íˆë“  í¬ê¸°
        """
        super().__init__()
        
        self.model_name = model_name
        self.input_channels = input_channels
        self.pretrained = pretrained
        self.dropout_rate = dropout_rate
        self.freeze_features = freeze_features
        self.num_fc_layers = num_fc_layers
        self.fc_hidden_size = fc_hidden_size
        
        # EfficientNet ë°±ë³¸ ë¡œë“œ
        self._load_backbone()
        
        # ì…ë ¥ ì±„ë„ ìˆ˜ì •
        if input_channels != 3:
            self._modify_input_layer()
        
        # íŠ¹ì„± ì¶”ì¶œ ë ˆì´ì–´ ê³ ì •
        if freeze_features:
            self._freeze_features()
        
        # ë¶„ë¥˜ê¸° êµì²´ (íšŒê·€ìš©)
        self._build_regression_head()
        
    def _load_backbone(self):
        """EfficientNet ë°±ë³¸ ë¡œë“œ"""
        model_dict = {
            'efficientnet_b0': models.efficientnet_b0,
            'efficientnet_b1': models.efficientnet_b1,
            'efficientnet_b2': models.efficientnet_b2,
            'efficientnet_b3': models.efficientnet_b3,
            'efficientnet_b4': models.efficientnet_b4,
            'efficientnet_b5': models.efficientnet_b5,
            'efficientnet_b6': models.efficientnet_b6,
            'efficientnet_b7': models.efficientnet_b7,
        }
        
        if self.model_name not in model_dict:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤: {self.model_name}")
        
        # PyTorch ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ë¡œë“œ
        if self.pretrained:
            self.backbone = model_dict[self.model_name](weights='DEFAULT')
        else:
            self.backbone = model_dict[self.model_name](weights=None)
        
    def _modify_input_layer(self):
        """ì…ë ¥ ì±„ë„ì— ë§ê²Œ ì²« ë²ˆì§¸ ë ˆì´ì–´ ìˆ˜ì •"""
        # EfficientNetì˜ ì²« ë²ˆì§¸ ë ˆì´ì–´ ìˆ˜ì •
        # ê°„ë‹¨í•˜ê²Œ 3x3 convë¡œ êµì²´
        new_conv = nn.Conv2d(
            in_channels=self.input_channels,
            out_channels=32,  # EfficientNet-B0 ê¸°ë³¸ê°’
            kernel_size=3,
            stride=2,
            padding=1,
            bias=False
        )
        
        # ì²« ë²ˆì§¸ Conv2d ë ˆì´ì–´ êµì²´
        for i, module in enumerate(self.backbone.features[0]):
            if isinstance(module, nn.Conv2d):
                self.backbone.features[0][i] = new_conv
                break
        
    def _freeze_features(self):
        """íŠ¹ì„± ì¶”ì¶œ ë ˆì´ì–´ ê³ ì •"""
        for param in self.backbone.features.parameters():
            param.requires_grad = False
            
    def _build_regression_head(self):
        """íšŒê·€ìš© ë¶„ë¥˜ê¸° í—¤ë“œ êµ¬ì„±"""
        # ê¸°ì¡´ ë¶„ë¥˜ê¸°ì˜ ì…ë ¥ ì°¨ì› í™•ì¸ (EfficientNet-B0: 1280)
        in_features = 1280  # EfficientNet-B0 ê¸°ë³¸ê°’
        
        # ìƒˆë¡œìš´ íšŒê·€ í—¤ë“œ êµ¬ì„±
        layers = []
        current_size = in_features
        
        # ì—¬ëŸ¬ ì€ë‹‰ì¸µ ì¶”ê°€
        for i in range(self.num_fc_layers - 1):
            layers.extend([
                nn.Linear(current_size, self.fc_hidden_size),
                nn.ReLU(inplace=True),
                nn.Dropout(p=self.dropout_rate)
            ])
            current_size = self.fc_hidden_size
        
        # ìµœì¢… ì¶œë ¥ì¸µ
        layers.append(nn.Linear(current_size, 1))
        
        # ë¶„ë¥˜ê¸° êµì²´
        self.backbone.classifier = nn.Sequential(*layers)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """ìˆœì „íŒŒ"""
        if x.dim() != 4:
            raise ValueError(f"ì…ë ¥ì€ 4ì°¨ì› í…ì„œì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {x.dim()}ì°¨ì›")
        
        if x.size(1) != self.input_channels:
            raise ValueError(f"ì…ë ¥ ì±„ë„ ìˆ˜ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ: {self.input_channels}, í˜„ì¬: {x.size(1)}")
        
        return self.backbone(x)
    
    def get_feature_maps(self, x: torch.Tensor, layer_idx: Optional[int] = None) -> torch.Tensor:
        """
        ì¤‘ê°„ íŠ¹ì„± ë§µ ì¶”ì¶œ (ì‹œê°í™”ìš©)
        
        Args:
            x (torch.Tensor): ì…ë ¥ í…ì„œ
            layer_idx (int, optional): ì¶”ì¶œí•  ë ˆì´ì–´ ì¸ë±ìŠ¤
            
        Returns:
            torch.Tensor: íŠ¹ì„± ë§µ
        """
        if layer_idx is None:
            layer_idx = len(self.backbone.features) - 1
        
        with torch.no_grad():
            for i, layer in enumerate(self.backbone.features):
                x = layer(x)
                if i == layer_idx:
                    return x
        
        return x
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'model_name': f'EfficientNetWatermelon_{self.model_name}',
            'backbone': self.model_name,
            'input_channels': self.input_channels,
            'pretrained': self.pretrained,
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'frozen_features': self.freeze_features,
            'dropout_rate': self.dropout_rate,
            'fc_layers': self.num_fc_layers,
            'fc_hidden_size': self.fc_hidden_size
        }
    
    def print_model_info(self):
        """ëª¨ë¸ ì •ë³´ ì¶œë ¥"""
        info = self.get_model_info()
        print(f"ğŸ¤– {info['model_name']} ëª¨ë¸ ì •ë³´")
        print(f"   ğŸ“Š ë°±ë³¸: {info['backbone']}")
        print(f"   ğŸ”§ ì…ë ¥ ì±„ë„: {info['input_channels']}")
        print(f"   ğŸ¯ ì‚¬ì „ í›ˆë ¨: {info['pretrained']}")
        print(f"   ğŸ“ˆ ì´ íŒŒë¼ë¯¸í„°: {info['total_parameters']:,}")
        print(f"   ğŸ”“ í›ˆë ¨ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {info['trainable_parameters']:,}")
        print(f"   â„ï¸ íŠ¹ì„± ê³ ì •: {info['frozen_features']}")
        print(f"   ğŸ’§ ë“œë¡­ì•„ì›ƒ: {info['dropout_rate']}")
        print(f"   ğŸ”— FC ë ˆì´ì–´: {info['fc_layers']}ê°œ")
        print(f"   ğŸ“ FC íˆë“  í¬ê¸°: {info['fc_hidden_size']}")


def create_efficientnet_watermelon(config_path: Optional[str] = None, **kwargs) -> EfficientNetWatermelon:
    """
    ì„¤ì • íŒŒì¼ ë˜ëŠ” í‚¤ì›Œë“œ ì¸ìë¡œë¶€í„° EfficientNetWatermelon ëª¨ë¸ ìƒì„±
    
    Args:
        config_path (str, optional): ëª¨ë¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        **kwargs: ëª¨ë¸ íŒŒë¼ë¯¸í„° (config_pathë³´ë‹¤ ìš°ì„ )
        
    Returns:
        EfficientNetWatermelon: ìƒì„±ëœ ëª¨ë¸
    """
    # ê¸°ë³¸ ì„¤ì •
    default_config = {
        'model_name': 'efficientnet_b0',
        'input_channels': 3,
        'pretrained': True,
        'dropout_rate': 0.7,
        'freeze_features': False,
        'num_fc_layers': 2,
        'fc_hidden_size': 256
    }
    
    # ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ
    if config_path:
        config_path = Path(config_path)
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                file_config = yaml.safe_load(f)
                default_config.update(file_config.get('model', {}))
    
    # í‚¤ì›Œë“œ ì¸ìë¡œ ë®ì–´ì“°ê¸°
    default_config.update(kwargs)
    
    return EfficientNetWatermelon(**default_config)


def load_efficientnet_checkpoint(checkpoint_path: str, 
                                model_config: Optional[Dict[str, Any]] = None) -> EfficientNetWatermelon:
    """
    ì²´í¬í¬ì¸íŠ¸ì—ì„œ EfficientNet ëª¨ë¸ ë¡œë“œ
    
    Args:
        checkpoint_path (str): ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
        model_config (dict, optional): ëª¨ë¸ ì„¤ì • (ì—†ìœ¼ë©´ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œ)
        
    Returns:
        EfficientNetWatermelon: ë¡œë“œëœ ëª¨ë¸
    """
    checkpoint_path = Path(checkpoint_path)
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    
    # ëª¨ë¸ ì„¤ì • í™•ì¸
    if model_config is None:
        model_config = checkpoint.get('model_config', {})
    
    # ëª¨ë¸ ìƒì„±
    model = EfficientNetWatermelon(**model_config)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.load_state_dict(checkpoint['model_state_dict'])
    
    return model


def save_efficientnet_checkpoint(model: EfficientNetWatermelon, 
                                save_path: str, 
                                epoch: Optional[int] = None,
                                loss: Optional[float] = None,
                                optimizer_state: Optional[Dict] = None,
                                **extra_info):
    """
    EfficientNet ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    
    Args:
        model (EfficientNetWatermelon): ì €ì¥í•  ëª¨ë¸
        save_path (str): ì €ì¥ ê²½ë¡œ
        epoch (int, optional): ì—í¬í¬ ë²ˆí˜¸
        loss (float, optional): ì†ì‹¤ ê°’
        optimizer_state (dict, optional): ì˜µí‹°ë§ˆì´ì € ìƒíƒœ
        **extra_info: ì¶”ê°€ ì •ë³´
    """
    save_path = Path(save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ì²´í¬í¬ì¸íŠ¸ ë°ì´í„° êµ¬ì„±
    checkpoint = {
        'model_state_dict': model.state_dict(),
        'model_config': {
            'model_name': model.model_name,
            'input_channels': model.input_channels,
            'pretrained': model.pretrained,
            'dropout_rate': model.dropout_rate,
            'freeze_features': model.freeze_features,
            'num_fc_layers': model.num_fc_layers,
            'fc_hidden_size': model.fc_hidden_size
        },
        'model_info': model.get_model_info()
    }
    
    # ì„ íƒì  ì •ë³´ ì¶”ê°€
    if epoch is not None:
        checkpoint['epoch'] = epoch
    if loss is not None:
        checkpoint['loss'] = loss
    if optimizer_state is not None:
        checkpoint['optimizer_state_dict'] = optimizer_state
    
    # ì¶”ê°€ ì •ë³´ ë³‘í•©
    checkpoint.update(extra_info)
    
    # ì €ì¥
    torch.save(checkpoint, save_path)
    print(f"âœ… EfficientNet ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {save_path}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
    model = create_efficientnet_watermelon()
    model.print_model_info()
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    test_input = torch.randn(1, 3, 224, 224)
    output = model(test_input)
    print(f"ì¶œë ¥ í¬ê¸°: {output.shape}")
    print(f"ì¶œë ¥ ê°’: {output.item():.4f}") 