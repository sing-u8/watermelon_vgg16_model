"""
VGG-16 Based Watermelon Sweetness Prediction Model
ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ì„ ìœ„í•œ VGG-16 ê¸°ë°˜ CNN ëª¨ë¸
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models
from typing import Dict, Any, Optional
import yaml
from pathlib import Path


class VGGWatermelon(nn.Module):
    """
    VGG-16 ê¸°ë°˜ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸
    
    ë©œ-ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì…ë ¥ì„ ë°›ì•„ ë‹¹ë„ê°’ì„ íšŒê·€ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸
    """
    
    def __init__(self, 
                 input_channels: int = 3,
                 pretrained: bool = True,
                 dropout_rate: float = 0.5,
                 freeze_features: bool = False,
                 num_fc_layers: int = 2,
                 fc_hidden_size: int = 512):
        """
        VGGWatermelon ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            input_channels (int): ì…ë ¥ ì±„ë„ ìˆ˜ (ê¸°ë³¸ê°’: 3 - RGB)
            pretrained (bool): ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€
            dropout_rate (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
            freeze_features (bool): íŠ¹ì„± ì¶”ì¶œ ë ˆì´ì–´ ê³ ì • ì—¬ë¶€
            num_fc_layers (int): ì™„ì „ ì—°ê²° ë ˆì´ì–´ ìˆ˜
            fc_hidden_size (int): ì™„ì „ ì—°ê²° ë ˆì´ì–´ íˆë“  í¬ê¸°
        """
        super(VGGWatermelon, self).__init__()
        
        self.input_channels = input_channels
        self.pretrained = pretrained
        self.dropout_rate = dropout_rate
        self.freeze_features = freeze_features
        self.num_fc_layers = num_fc_layers
        self.fc_hidden_size = fc_hidden_size
        
        # VGG-16 ë°±ë³¸ ë¡œë“œ
        self.backbone = models.vgg16(pretrained=pretrained)
        
        # ì…ë ¥ ì±„ë„ì´ 3ì´ ì•„ë‹Œ ê²½ìš° ì²« ë²ˆì§¸ ë ˆì´ì–´ ìˆ˜ì •
        if input_channels != 3:
            self._modify_input_layer()
        
        # íŠ¹ì„± ì¶”ì¶œ ë ˆì´ì–´ ê³ ì •
        if freeze_features:
            self._freeze_features()
        
        # ë¶„ë¥˜ê¸° êµì²´ (íšŒê·€ìš©)
        self._build_regression_head()
        
    def _modify_input_layer(self):
        """ì…ë ¥ ì±„ë„ì— ë§ê²Œ ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ìˆ˜ì •"""
        # ì²« ë²ˆì§¸ ë ˆì´ì–´ê°€ Conv2dì¸ì§€ í™•ì¸
        features_list = list(self.backbone.features.children())
        if not isinstance(features_list[0], nn.Conv2d):
            raise ValueError("ì²« ë²ˆì§¸ ë ˆì´ì–´ê°€ Conv2dê°€ ì•„ë‹™ë‹ˆë‹¤.")
        
        original_conv = features_list[0]
        
        # ìƒˆë¡œìš´ ì²« ë²ˆì§¸ ë ˆì´ì–´ ìƒì„±
        new_conv = nn.Conv2d(
            in_channels=self.input_channels,
            out_channels=original_conv.out_channels,
            kernel_size=original_conv.kernel_size,
            stride=original_conv.stride,
            padding=original_conv.padding,
            bias=original_conv.bias is not None
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        if self.pretrained and self.input_channels == 1:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš° RGB ê°€ì¤‘ì¹˜ì˜ í‰ê·  ì‚¬ìš©
            with torch.no_grad():
                new_conv.weight[:, 0, :, :] = original_conv.weight.mean(dim=1)
        elif self.pretrained:
            # ë‹¤ë¥¸ ì±„ë„ ìˆ˜ì¸ ê²½ìš° ì ì ˆíˆ ì´ˆê¸°í™”
            with torch.no_grad():
                if self.input_channels < 3:
                    new_conv.weight[:, :self.input_channels, :, :] = \
                        original_conv.weight[:, :self.input_channels, :, :]
                else:
                    # ì±„ë„ ìˆ˜ê°€ ë” ë§ì€ ê²½ìš° ë°˜ë³µí•´ì„œ ì´ˆê¸°í™”
                    for i in range(self.input_channels):
                        new_conv.weight[:, i, :, :] = original_conv.weight[:, i % 3, :, :]
        
        # ë°±ë³¸ì˜ ì²« ë²ˆì§¸ ë ˆì´ì–´ êµì²´
        # Sequentialì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ êµì²´
        new_features = nn.Sequential(
            new_conv,
            *list(self.backbone.features.children())[1:]
        )
        self.backbone.features = new_features
    
    def _freeze_features(self):
        """íŠ¹ì„± ì¶”ì¶œ ë ˆì´ì–´ ê³ ì •"""
        for param in self.backbone.features.parameters():
            param.requires_grad = False
            
        # ì–´ëŒ‘í‹°ë¸Œ í’€ë§ ë ˆì´ì–´ë„ ê³ ì •
        for param in self.backbone.avgpool.parameters():
            param.requires_grad = False
    
    def _build_regression_head(self):
        """íšŒê·€ìš© ë¶„ë¥˜ê¸° í—¤ë“œ êµ¬ì„±"""
        # ì›ë³¸ ë¶„ë¥˜ê¸° ì œê±°
        classifier_list = list(self.backbone.classifier.children())
        if not isinstance(classifier_list[0], nn.Linear):
            raise ValueError("ì²« ë²ˆì§¸ ë¶„ë¥˜ê¸° ë ˆì´ì–´ê°€ Linearê°€ ì•„ë‹™ë‹ˆë‹¤.")
        
        in_features = classifier_list[0].in_features
        
        # ìƒˆë¡œìš´ íšŒê·€ í—¤ë“œ êµ¬ì„±
        layers = []
        current_size = in_features
        
        # ì—¬ëŸ¬ ì€ë‹‰ì¸µ ì¶”ê°€
        for i in range(self.num_fc_layers - 1):
            layers.extend([
                nn.Linear(current_size, self.fc_hidden_size),
                nn.ReLU(inplace=True),
                nn.Dropout(p=self.dropout_rate)
            ])
            current_size = self.fc_hidden_size
        
        # ìµœì¢… ì¶œë ¥ì¸µ (ë‹¹ë„ ì˜ˆì¸¡)
        layers.append(nn.Linear(current_size, 1))
        
        # ë¶„ë¥˜ê¸° êµì²´
        self.backbone.classifier = nn.Sequential(*layers)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        ìˆœì „íŒŒ
        
        Args:
            x (torch.Tensor): ì…ë ¥ í…ì„œ [batch_size, channels, height, width]
            
        Returns:
            torch.Tensor: ë‹¹ë„ ì˜ˆì¸¡ê°’ [batch_size, 1]
        """
        # ì…ë ¥ í¬ê¸° ê²€ì¦
        if x.dim() != 4:
            raise ValueError(f"ì…ë ¥ì€ 4ì°¨ì› í…ì„œì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {x.dim()}ì°¨ì›")
        
        if x.size(1) != self.input_channels:
            raise ValueError(f"ì…ë ¥ ì±„ë„ ìˆ˜ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ: {self.input_channels}, í˜„ì¬: {x.size(1)}")
        
        # VGG-16 ìˆœì „íŒŒ
        output = self.backbone(x)
        
        return output
    
    def get_feature_maps(self, x: torch.Tensor, layer_idx: Optional[int] = None) -> torch.Tensor:
        """
        ì¤‘ê°„ íŠ¹ì„± ë§µ ì¶”ì¶œ (ì‹œê°í™”ìš©)
        
        Args:
            x (torch.Tensor): ì…ë ¥ í…ì„œ
            layer_idx (int, optional): ì¶”ì¶œí•  ë ˆì´ì–´ ì¸ë±ìŠ¤
            
        Returns:
            torch.Tensor: íŠ¹ì„± ë§µ
        """
        if layer_idx is None:
            layer_idx = len(self.backbone.features) - 1
        
        with torch.no_grad():
            for i, layer in enumerate(self.backbone.features):
                x = layer(x)
                if i == layer_idx:
                    return x
        
        return x
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'model_name': 'VGGWatermelon',
            'backbone': 'VGG-16',
            'input_channels': self.input_channels,
            'pretrained': self.pretrained,
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'frozen_features': self.freeze_features,
            'dropout_rate': self.dropout_rate,
            'fc_layers': self.num_fc_layers,
            'fc_hidden_size': self.fc_hidden_size
        }
    
    def print_model_info(self):
        """ëª¨ë¸ ì •ë³´ ì¶œë ¥"""
        info = self.get_model_info()
        print(f"ğŸ¤– {info['model_name']} ëª¨ë¸ ì •ë³´")
        print(f"   ğŸ“Š ë°±ë³¸: {info['backbone']}")
        print(f"   ğŸ”§ ì…ë ¥ ì±„ë„: {info['input_channels']}")
        print(f"   ğŸ¯ ì‚¬ì „ í›ˆë ¨: {info['pretrained']}")
        print(f"   ğŸ“ˆ ì´ íŒŒë¼ë¯¸í„°: {info['total_parameters']:,}")
        print(f"   ğŸ”“ í›ˆë ¨ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {info['trainable_parameters']:,}")
        print(f"   â„ï¸ íŠ¹ì„± ê³ ì •: {info['frozen_features']}")
        print(f"   ğŸ’§ ë“œë¡­ì•„ì›ƒ: {info['dropout_rate']}")
        print(f"   ğŸ”— FC ë ˆì´ì–´: {info['fc_layers']}ê°œ")
        print(f"   ğŸ“ FC íˆë“  í¬ê¸°: {info['fc_hidden_size']}")


def create_vgg_watermelon(config_path: Optional[str] = None, **kwargs) -> VGGWatermelon:
    """
    ì„¤ì • íŒŒì¼ ë˜ëŠ” í‚¤ì›Œë“œ ì¸ìë¡œë¶€í„° VGGWatermelon ëª¨ë¸ ìƒì„±
    
    Args:
        config_path (str, optional): ëª¨ë¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        **kwargs: ëª¨ë¸ íŒŒë¼ë¯¸í„° (config_pathë³´ë‹¤ ìš°ì„ )
        
    Returns:
        VGGWatermelon: ìƒì„±ëœ ëª¨ë¸
    """
    # ê¸°ë³¸ ì„¤ì •
    default_config = {
        'input_channels': 3,
        'pretrained': True,
        'dropout_rate': 0.5,
        'freeze_features': False,
        'num_fc_layers': 2,
        'fc_hidden_size': 512
    }
    
    # ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ
    if config_path:
        config_path = Path(config_path)
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                file_config = yaml.safe_load(f)
                default_config.update(file_config.get('model', {}))
    
    # í‚¤ì›Œë“œ ì¸ìë¡œ ë®ì–´ì“°ê¸°
    default_config.update(kwargs)
    
    # ëª¨ë¸ ìƒì„±
    model = VGGWatermelon(**default_config)
    
    print(f"âœ… VGGWatermelon ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    if config_path:
        print(f"   ğŸ“„ ì„¤ì • íŒŒì¼: {config_path}")
    
    return model


def load_model_checkpoint(checkpoint_path: str, 
                         model_config: Optional[Dict[str, Any]] = None) -> VGGWatermelon:
    """
    ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ
    
    Args:
        checkpoint_path (str): ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
        model_config (dict, optional): ëª¨ë¸ ì„¤ì • (ì²´í¬í¬ì¸íŠ¸ì— ì—†ëŠ” ê²½ìš°)
        
    Returns:
        VGGWatermelon: ë¡œë“œëœ ëª¨ë¸
    """
    checkpoint_path = Path(checkpoint_path)
    
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # ëª¨ë¸ ì„¤ì • ì¶”ì¶œ
    if 'model_config' in checkpoint:
        config = checkpoint['model_config']
    elif model_config is not None:
        config = model_config
    else:
        raise ValueError("ëª¨ë¸ ì„¤ì •ì´ ì²´í¬í¬ì¸íŠ¸ì— ì—†ê³  ë³„ë„ë¡œ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
    model = VGGWatermelon(**config)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    print(f"âœ… ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {checkpoint_path}")
    if 'epoch' in checkpoint:
        print(f"   ğŸ“Š ì—í¬í¬: {checkpoint['epoch']}")
    if 'loss' in checkpoint:
        print(f"   ğŸ“‰ ì†ì‹¤: {checkpoint['loss']:.4f}")
    
    return model


def save_model_checkpoint(model: VGGWatermelon, 
                         save_path: str, 
                         epoch: Optional[int] = None,
                         loss: Optional[float] = None,
                         optimizer_state: Optional[Dict] = None,
                         **extra_info):
    """
    ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    
    Args:
        model (VGGWatermelon): ì €ì¥í•  ëª¨ë¸
        save_path (str): ì €ì¥ ê²½ë¡œ
        epoch (int, optional): í˜„ì¬ ì—í¬í¬
        loss (float, optional): í˜„ì¬ ì†ì‹¤
        optimizer_state (dict, optional): ì˜µí‹°ë§ˆì´ì € ìƒíƒœ
        **extra_info: ì¶”ê°€ ì •ë³´
    """
    save_path = Path(save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ì €ì¥í•  ì •ë³´ êµ¬ì„±
    checkpoint = {
        'model_state_dict': model.state_dict(),
        'model_config': model.get_model_info()
    }
    
    if epoch is not None:
        checkpoint['epoch'] = epoch
    if loss is not None:
        checkpoint['loss'] = loss
    if optimizer_state is not None:
        checkpoint['optimizer_state_dict'] = optimizer_state
    
    # ì¶”ê°€ ì •ë³´ ì €ì¥
    checkpoint.update(extra_info)
    
    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    torch.save(checkpoint, save_path)
    
    print(f"ğŸ’¾ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {save_path}")


if __name__ == "__main__":
    # ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª VGGWatermelon ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    
    # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
    model = create_vgg_watermelon()
    model.print_model_info()
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    batch_size = 4
    channels = 3
    height, width = 224, 224
    
    test_input = torch.randn(batch_size, channels, height, width)
    
    # ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
    model.eval()
    with torch.no_grad():
        output = model(test_input)
        print(f"\nâœ… ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        print(f"   ì…ë ¥ í¬ê¸°: {test_input.shape}")
        print(f"   ì¶œë ¥ í¬ê¸°: {output.shape}")
        print(f"   ì˜ˆì¸¡ ë‹¹ë„: {output.squeeze().tolist()}") 